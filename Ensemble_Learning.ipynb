{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A voting classifier is a machine learning estimator that trains various base models or estimators and predicts on the basis of aggregating the findings of each base estimator.\n",
    "\n",
    "\n",
    "We can implement the voting classifier in 2 ways:\n",
    "\n",
    "\n",
    "**Majority Voting**\n",
    "\n",
    "\n",
    "Every model makes a prediction (votes) for each test instance and the final output prediction is the one that receives **more than half of the votes**. If none of the predictions get more than half of the votes, we may say that the ensemble method could not make a stable prediction for this instance.\n",
    "\n",
    "\n",
    "**Weighted Voting**\n",
    "\n",
    "\n",
    "Unlike majority voting, where each model has the same weights, we can increase the importance of one or more models. In weighted voting we count the prediction of the better models **multiple times**.\n",
    "\n",
    "\n",
    "So in general, in ensemble methods, instead of learning a weak classifier, we learn **many weak classifiers** that are good at different parts of the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I import the libraries that needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing the ensemble algorithm, I **preprocess** the data, since there is **missing data** in the columns.\n",
    "I replace the missing values with the **mean of the column** as implemented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/Nika/Desktop/cancer.csv\")\n",
    "Bare_Nuclei_column = data[\"Bare Nuclei\"]\n",
    "Bare_Nuclei_column.drop(Bare_Nuclei_column.index[Bare_Nuclei_column == '?'], inplace=True)\n",
    "Bare_Nuclei_column = Bare_Nuclei_column.values.tolist()\n",
    "for i in range (len(Bare_Nuclei_column)):\n",
    "    Bare_Nuclei_column[i] = int(Bare_Nuclei_column[i])\n",
    "Bare_Nuclei_mean = mean(Bare_Nuclei_column)\n",
    "data[\"Bare Nuclei\"].replace({\"?\": Bare_Nuclei_mean}, inplace=True)\n",
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I process the dataset by implementing **K-fold cross-validation** with k = 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = pd.DataFrame(data, columns=[\"Clump Thickness\",\"Uniformity of Cell Size\",\"Uniformity of Cell Shape\",\"Marginal Adhesion\",\"Single Epithelial Cell Size\",\"Bare Nuclei\",\"Bland Chromatin\",\"Normal Nucleoli\",\"Mitoses\"])\n",
    "ys = pd.DataFrame(data, columns=[\"Class\"])\n",
    "y = np.asarray(ys[\"Class\"])\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is ready, I implement the **Ensemble Learning** algorithm with **Random Forest**, **SVM**, and **Logistic Regression** with **voting classifier** as below, and report the average accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy: 0.9699792960662528\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)])\n",
    "result = cross_val_score(voting_clf , Xs, y, cv = kf)\n",
    "print(\"Avg accuracy: {}\".format(result.mean()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeab3e71adb6dbd0e75fb9a8c9bdb5e7c4aba7cf3fd60c4dcf30c1777b01516d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
